//! Module de lecture audio utilisant cpal
//! 
//! Ce module impl√©mente le trait AudioPlayback en utilisant la librairie cpal
//! pour jouer l'audio via les haut-parleurs ou casque.
//!
//! La lecture audio est plus complexe que la capture car elle n√©cessite :
//! - Un buffer pour g√©rer le jitter r√©seau
//! - Une gestion des underruns (pas assez de donn√©es)
//! - Une synchronisation avec l'horloge syst√®me

use async_trait::async_trait;
use cpal::{Device, Stream, SupportedStreamConfig, SampleFormat};
use cpal::traits::{HostTrait, DeviceTrait, StreamTrait};
use tokio::sync::Mutex;
use std::collections::VecDeque;
use std::sync::Arc;

use crate::{
    AudioPlayback, AudioFrame, AudioConfig, AudioError, AudioResult,
};

/// Impl√©mentation de lecture audio avec cpal
/// 
/// Cette structure g√®re :
/// - La d√©couverte du p√©riph√©rique de lecture (haut-parleurs)
/// - La configuration du stream audio de sortie
/// - Le buffering des frames pour g√©rer le jitter r√©seau
/// - La conversion de nos AudioFrame vers les √©chantillons cpal
/// 
/// # Architecture thread
/// 
/// Le thread principal ajoute des frames au buffer via `play_frame()`.
/// Le callback cpal (thread temps r√©el) lit le buffer et envoie les 
/// √©chantillons vers le hardware audio.
pub struct CpalPlayback {
    /// P√©riph√©rique audio de sortie (haut-parleurs)
    device: Device,
    
    /// Configuration audio de notre application
    config: AudioConfig,
    
    /// Stream audio actif (None si arr√™t√©)
    stream: Option<Stream>,
    
    /// Buffer principal des frames en attente de lecture
    /// Prot√©g√© par un Arc<Mutex> pour acc√®s thread-safe
    frame_buffer: Arc<Mutex<VecDeque<AudioFrame>>>,
    
    /// √âtat de la lecture
    is_playing: bool,
    
    /// Nom du p√©riph√©rique pour debug
    device_name: String,
    
    /// Compteur de frames jou√©es (statistiques)
    frames_played: Arc<Mutex<u64>>,
    
    /// Compteur d'underruns (manque de donn√©es)
    underruns: Arc<Mutex<u64>>,
}

impl CpalPlayback {
    /// Cr√©e une nouvelle instance de lecture
    /// 
    /// Cette fonction d√©couvre automatiquement le p√©riph√©rique de sortie par d√©faut
    /// et pr√©pare la configuration, mais ne d√©marre pas encore la lecture.
    /// 
    /// # Arguments
    /// * `config` - Configuration audio √† utiliser
    /// 
    /// # Erreurs
    /// - `AudioError::NoDeviceFound` si aucun haut-parleur n'est disponible
    /// - `AudioError::ConfigError` si la configuration n'est pas support√©e
    pub fn new(config: AudioConfig) -> AudioResult<Self> {
        // Obtient l'host audio par d√©faut du syst√®me
        let host = cpal::default_host();
        
        // Trouve le p√©riph√©rique de sortie par d√©faut
        let device = host
            .default_output_device()
            .ok_or(AudioError::NoDeviceFound)?;
            
        // R√©cup√®re le nom du p√©riph√©rique pour debug
        let device_name = device.description()
            .ok()
            .map(|desc| desc.name().to_string())
            .unwrap_or_else(|| "P√©riph√©rique inconnu".to_string());
            
        // Cr√©e le buffer avec la taille configur√©e
        let frame_buffer = Arc::new(Mutex::new(VecDeque::with_capacity(
            config.receive_buffer_size * 2 // Un peu plus grand pour √©viter les reallocations
        )));
        
        println!("üîä P√©riph√©rique de lecture trouv√© : {}", device_name);
        
        Ok(Self {
            device,
            config,
            stream: None,
            frame_buffer,
            is_playing: false,
            device_name,
            frames_played: Arc::new(Mutex::new(0)),
            underruns: Arc::new(Mutex::new(0)),
        })
    }
    
    /// V√©rifie que la configuration audio est support√©e par le p√©riph√©rique
    fn validate_config(&self) -> AudioResult<SupportedStreamConfig> {
        // Obtient la configuration par d√©faut du p√©riph√©rique
        let default_config = self.device
            .default_output_config()
            .map_err(|e| AudioError::ConfigError(format!("Impossible d'obtenir config par d√©faut: {}", e)))?;
        
        println!("üìã Config par d√©faut du p√©riph√©rique de sortie :");
        println!("   Sample rate: {} Hz", default_config.sample_rate());
        println!("   Channels: {}", default_config.channels());
        println!("   Sample format: {:?}", default_config.sample_format());
        
        // V√©rifie que le p√©riph√©rique supporte notre sample rate
        let supported_rates = self.device
            .supported_output_configs()
            .map_err(|e| AudioError::ConfigError(format!("Impossible d'obtenir configs support√©es: {}", e)))?;
        
        let mut config_found = false;
        for supported_range in supported_rates {
            let min_rate = supported_range.min_sample_rate();
            let max_rate = supported_range.max_sample_rate();
            
            if self.config.sample_rate >= min_rate && self.config.sample_rate <= max_rate {
                config_found = true;
                break;
            }
        }
        
        if !config_found {
            return Err(AudioError::ConfigError(format!(
                "Sample rate {} Hz non support√© par le p√©riph√©rique de sortie", 
                self.config.sample_rate
            )));
        }
        
        
        Ok(default_config)
    }
    
    /// Construit et configure le stream audio de sortie
    fn build_stream(&mut self) -> AudioResult<Stream> {
        let stream_config = self.validate_config()?;
        
        // Clone des variables n√©cessaires pour le callback
        let frame_buffer = Arc::clone(&self.frame_buffer);
        let samples_per_frame = self.config.samples_per_frame();
        let frames_played = Arc::clone(&self.frames_played);
        let underruns = Arc::clone(&self.underruns);
        
        println!("üéµ D√©marrage lecture :");
        println!("   √âchantillons par frame : {}", samples_per_frame);
        println!("   Taille buffer : {} frames", self.config.receive_buffer_size);
        
        // Buffer local pour accumuler les √©chantillons
        let mut output_buffer = VecDeque::with_capacity(samples_per_frame * 4);
        
        // D√©termine le format d'√©chantillons du p√©riph√©rique
        let sample_format = stream_config.sample_format();
        
        // Construit le stream selon le format d'√©chantillons
        let stream = match sample_format {
            SampleFormat::F32 => {
                self.device.build_output_stream(
                    &stream_config.config(),
                    move |data: &mut [f32], _: &cpal::OutputCallbackInfo| {
                        Self::fill_output_buffer_f32(
                            data,
                            &mut output_buffer,
                            &frame_buffer,
                            samples_per_frame,
                            &frames_played,
                            &underruns,
                        );
                    },
                    move |err| {
                        eprintln!("‚ùå Erreur stream audio sortie : {}", err);
                    },
                    None
                )?
            },
            SampleFormat::I16 => {
                self.device.build_output_stream(
                    &stream_config.config(),
                    move |data: &mut [i16], _: &cpal::OutputCallbackInfo| {
                        Self::fill_output_buffer_i16(
                            data,
                            &mut output_buffer,
                            &frame_buffer,
                            samples_per_frame,
                            &frames_played,
                            &underruns,
                        );
                    },
                    move |err| {
                        eprintln!("‚ùå Erreur stream audio sortie : {}", err);
                    },
                    None
                )?
            },
            SampleFormat::U16 => {
                self.device.build_output_stream(
                    &stream_config.config(),
                    move |data: &mut [u16], _: &cpal::OutputCallbackInfo| {
                        Self::fill_output_buffer_u16(
                            data,
                            &mut output_buffer,
                            &frame_buffer,
                            samples_per_frame,
                            &frames_played,
                            &underruns,
                        );
                    },
                    move |err| {
                        eprintln!("‚ùå Erreur stream audio sortie : {}", err);
                    },
                    None
                )?
            },
            _ => return Err(AudioError::ConfigError(format!("Format d'√©chantillon non support√© : {:?}", sample_format))),
        };
        
        Ok(stream)
    }
    
    /// Remplit le buffer de sortie avec des √©chantillons f32
    /// 
    /// Cette fonction est appel√©e par le callback audio (thread temps r√©el).
    /// Elle doit √™tre tr√®s rapide et ne jamais bloquer.
    fn fill_output_buffer_f32(
        output: &mut [f32],
        sample_buffer: &mut VecDeque<f32>,
        frame_buffer: &Arc<Mutex<VecDeque<AudioFrame>>>,
        _samples_per_frame: usize,
        frames_played: &Arc<Mutex<u64>>,
        underruns: &Arc<Mutex<u64>>,
    ) {
        // Remplit le buffer d'√©chantillons si n√©cessaire
        while sample_buffer.len() < output.len() {
            // Essaie de r√©cup√©rer une frame (non-bloquant)
            if let Ok(mut buffer_guard) = frame_buffer.try_lock() {
                if let Some(frame) = buffer_guard.pop_front() {
                    // Ajoute tous les √©chantillons de cette frame
                    for sample in frame.samples {
                        sample_buffer.push_back(sample);
                    }
                    
                    // Met √† jour les statistiques (non-bloquant)
                    if let Ok(mut count) = frames_played.try_lock() {
                        *count += 1;
                    }
                } else {
                    // Pas de frame disponible - underrun
                    if let Ok(mut count) = underruns.try_lock() {
                        *count += 1;
                    }
                    break;
                }
            } else {
                // Impossible d'obtenir le lock - on continue avec ce qu'on a
                break;
            }
        }
        
        // Remplit la sortie avec les √©chantillons disponibles
        for sample in output.iter_mut() {
            *sample = sample_buffer.pop_front().unwrap_or(0.0); // Silence si pas de donn√©es
        }
    }
    
    /// Remplit le buffer de sortie avec des √©chantillons i16 (conversion depuis f32)
    fn fill_output_buffer_i16(
        output: &mut [i16],
        sample_buffer: &mut VecDeque<f32>,
        frame_buffer: &Arc<Mutex<VecDeque<AudioFrame>>>,
        _samples_per_frame: usize,
        frames_played: &Arc<Mutex<u64>>,
        underruns: &Arc<Mutex<u64>>,
    ) {
        // M√™me logique que f32, mais on convertit en remplissant
        while sample_buffer.len() < output.len() {
            if let Ok(mut buffer_guard) = frame_buffer.try_lock() {
                if let Some(frame) = buffer_guard.pop_front() {
                    for sample in frame.samples {
                        sample_buffer.push_back(sample);
                    }
                    
                    if let Ok(mut count) = frames_played.try_lock() {
                        *count += 1;
                    }
                } else {
                    if let Ok(mut count) = underruns.try_lock() {
                        *count += 1;
                    }
                    break;
                }
            } else {
                break;
            }
        }
        
        // Remplit et convertit f32 -> i16
        for sample in output.iter_mut() {
            let f32_sample = sample_buffer.pop_front().unwrap_or(0.0);
            // Convertit f32 [-1.0, 1.0] vers i16
            *sample = (f32_sample * i16::MAX as f32) as i16;
        }
    }
    
    /// Remplit le buffer de sortie avec des √©chantillons u16 (conversion depuis f32)
    fn fill_output_buffer_u16(
        output: &mut [u16],
        sample_buffer: &mut VecDeque<f32>,
        frame_buffer: &Arc<Mutex<VecDeque<AudioFrame>>>,
        _samples_per_frame: usize,
        frames_played: &Arc<Mutex<u64>>,
        underruns: &Arc<Mutex<u64>>,
    ) {
        // M√™me logique que f32, mais on convertit en remplissant
        while sample_buffer.len() < output.len() {
            if let Ok(mut buffer_guard) = frame_buffer.try_lock() {
                if let Some(frame) = buffer_guard.pop_front() {
                    for sample in frame.samples {
                        sample_buffer.push_back(sample);
                    }
                    
                    if let Ok(mut count) = frames_played.try_lock() {
                        *count += 1;
                    }
                } else {
                    if let Ok(mut count) = underruns.try_lock() {
                        *count += 1;
                    }
                    break;
                }
            } else {
                break;
            }
        }
        
        // Remplit et convertit f32 -> u16
        for sample in output.iter_mut() {
            let f32_sample = sample_buffer.pop_front().unwrap_or(0.0);
            // Convertit f32 [-1.0, 1.0] vers u16 [0, 65535]
            *sample = ((f32_sample + 1.0) * 0.5 * u16::MAX as f32) as u16;
        }
    }
    
    /// Retourne les statistiques de lecture
    pub async fn get_stats(&self) -> (u64, u64) {
        let frames = *self.frames_played.lock().await;
        let underruns = *self.underruns.lock().await;
        (frames, underruns)
    }
}

#[async_trait]
impl AudioPlayback for CpalPlayback {
    async fn start(&mut self) -> AudioResult<()> {
        if self.is_playing {
            return Ok(()); // D√©j√† d√©marr√©
        }
        
        println!("üöÄ D√©marrage de la lecture audio...");
        
        // Construit et d√©marre le stream
        let stream = self.build_stream()?;
        stream.play()?;
        
        self.stream = Some(stream);
        self.is_playing = true;
        
        println!("‚úÖ Lecture audio d√©marr√©e");
        Ok(())
    }
    
    async fn stop(&mut self) -> AudioResult<()> {
        if !self.is_playing {
            return Ok(()); // D√©j√† arr√™t√©
        }
        
        println!("üõë Arr√™t de la lecture audio...");
        
        // Arr√™te et supprime le stream
        if let Some(stream) = self.stream.take() {
            stream.pause()?;
        }
        
        self.is_playing = false;
        
        println!("‚úÖ Lecture audio arr√™t√©e");
        Ok(())
    }
    
    async fn play_frame(&mut self, frame: AudioFrame) -> AudioResult<()> {
        let mut buffer_guard = self.frame_buffer.lock().await;
        
        // V√©rifie si le buffer est plein
        if buffer_guard.len() >= self.config.receive_buffer_size {
            // Buffer plein - on peut soit dropper la frame la plus ancienne,
            // soit rejeter la nouvelle frame
            buffer_guard.pop_front(); // Drop la plus ancienne
            return Err(AudioError::BufferOverflow);
        }
        
        // Ajoute la frame au buffer
        buffer_guard.push_back(frame);
        Ok(())
    }
    
    fn is_playing(&self) -> bool {
        self.is_playing
    }
    
    fn buffer_level(&self) -> usize {
        // Note: try_lock pour √©viter de bloquer si appel√© depuis un callback
        if let Ok(buffer_guard) = self.frame_buffer.try_lock() {
            buffer_guard.len()
        } else {
            0 // Estimation si on ne peut pas lock
        }
    }
    
    async fn flush_buffer(&mut self) -> AudioResult<()> {
        let mut buffer_guard = self.frame_buffer.lock().await;
        buffer_guard.clear();
        println!("üóëÔ∏è  Buffer de lecture vid√©");
        Ok(())
    }
    
    fn device_info(&self) -> String {
        self.device_name.clone()
    }
}

// Impl√©mentation de Drop pour nettoyer proprement
impl Drop for CpalPlayback {
    fn drop(&mut self) {
        if self.is_playing {
            println!("üßπ Nettoyage automatique de la lecture audio");
            // Note: on ne peut pas appeler stop() ici car c'est async
            // Le stream sera automatiquement arr√™t√© quand il sera dropped
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::{sleep, Duration};
    
    #[test]
    fn test_playback_creation() {
        let config = AudioConfig::default();
        
        // Test que la cr√©ation ne panic pas
        match CpalPlayback::new(config) {
            Ok(playback) => {
                assert!(!playback.is_playing());
                assert!(!playback.device_info().is_empty());
                assert_eq!(playback.buffer_level(), 0);
            },
            Err(AudioError::NoDeviceFound) => {
                println!("‚ö†Ô∏è  Pas de haut-parleur disponible pour le test");
            },
            Err(e) => panic!("Erreur inattendue: {}", e),
        }
    }
    
    #[tokio::test]
    async fn test_playback_start_stop() {
        let config = AudioConfig::default();
        
        if let Ok(mut playback) = CpalPlayback::new(config) {
            // Test start/stop basique
            assert!(!playback.is_playing());
            
            if playback.start().await.is_ok() {
                assert!(playback.is_playing());
                
                if playback.stop().await.is_ok() {
                    assert!(!playback.is_playing());
                }
            }
        }
    }
    
    #[tokio::test]
    async fn test_playback_buffer() {
        let config = AudioConfig::default();
        
        if let Ok(mut playback) = CpalPlayback::new(config.clone()) {
            assert_eq!(playback.buffer_level(), 0);
            
            // Ajoute des frames au buffer
            for i in 0..3 {
                let frame = AudioFrame::silence(config.samples_per_frame(), i);
                if playback.play_frame(frame).await.is_ok() {
                    assert_eq!(playback.buffer_level(), (i + 1) as usize);
                }
            }
            
            // Test flush
            if playback.flush_buffer().await.is_ok() {
                assert_eq!(playback.buffer_level(), 0);
            }
        }
    }
    
    #[tokio::test]
    async fn test_playback_buffer_overflow() {
        let config = AudioConfig::default();
        
        if let Ok(mut playback) = CpalPlayback::new(config.clone()) {
            // Remplit le buffer au maximum
            for i in 0..config.receive_buffer_size {
                let frame = AudioFrame::silence(config.samples_per_frame(), i as u64);
                let result = playback.play_frame(frame).await;
                assert!(result.is_ok());
            }
            
            // Une frame de plus doit causer un overflow
            let overflow_frame = AudioFrame::silence(config.samples_per_frame(), 999);
            let result = playback.play_frame(overflow_frame).await;
            assert!(matches!(result, Err(AudioError::BufferOverflow)));
        }
    }
    
    // Note: Ce test n√©cessite de vrais haut-parleurs et peut √™tre audible
    #[tokio::test]
    #[ignore] // Ignore par d√©faut, lance avec --ignored pour tester
    async fn test_playback_audio() {
        let config = AudioConfig::default();
        
        if let Ok(mut playback) = CpalPlayback::new(config.clone()) {
            if playback.start().await.is_ok() {
                println!("üîä Test audio en cours - vous devriez entendre des bips...");
                
                // G√©n√®re et joue plusieurs bips
                for freq in &[440.0, 523.0, 659.0] { // Do, Mi, Sol
                    let samples_per_frame = config.samples_per_frame();
                    let sample_rate = config.sample_rate as f32;
                    
                    // G√©n√®re un bip de 100ms
                    for frame_idx in 0..5 { // 5 frames * 20ms = 100ms
                        let mut beep_samples = Vec::with_capacity(samples_per_frame);
                        for i in 0..samples_per_frame {
                            let t = (frame_idx * samples_per_frame + i) as f32 / sample_rate;
                            let sample = (2.0 * std::f32::consts::PI * freq * t).sin() * 0.3;
                            beep_samples.push(sample);
                        }
                        
                        let beep_frame = AudioFrame::new(beep_samples, frame_idx as u64);
                        if playback.play_frame(beep_frame).await.is_err() {
                            break;
                        }
                    }
                    
                    // Pause entre les bips
                    sleep(Duration::from_millis(200)).await;
                }
                
                // Attend que tout soit jou√©
                sleep(Duration::from_millis(500)).await;
                
                let (frames_played, underruns) = playback.get_stats().await;
                println!("üìä Statistiques lecture :");
                println!("   Frames jou√©es : {}", frames_played);
                println!("   Underruns : {}", underruns);
                
                let _ = playback.stop().await;
            }
        }
    }
}
